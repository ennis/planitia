 ✔ Create window with DXGI Swapchain & vulkan interop @done (25-08-03 17:11)
 ✔ Import graal @done (25-08-03 17:11)
 ✔ Input events @done (25-08-03 17:43)
 ✔ Simple rendering (clear color) @done (25-08-03 18:22)
 ✔ Unify statics in a single context struct @done (25-08-03 20:25)
 ✔ timers @done (25-08-21 23:33)
 ✔ collect input events @done (25-08-06 16:50)
 ✔ non-async loop handler @done (25-08-21 23:33)
 ✔ move compositor clock thread to separate module @done (25-08-22 12:36)
 ✔ quit on close @done (25-08-21 23:34)
 ✔ egui integration @done (25-08-23 17:46)
 ✔ Skip frame if late (late vsync event) @done (25-08-24 12:50)
 ☐ Create entity / serialize
 ✔ imgui: handle window resize @done (25-08-23 23:38)
 ✔ Make things debuggable with renderdoc @done (25-08-23 23:38)
 ✔ Fix egui freezing sometimes @done (25-08-23 22:28)
 ✔ Fix egui color bug @done (25-08-23 23:15)
     It was a nasty use-after-free due to slice::from_raw_parts ignoring lifetimes
 ☐ Use vulkan swapchains instead of DXGI, to make things simpler to debug @low
 ✔ Replace uses of `Device::global().function` by global functions. @done (25-11-01 10:37)
 ✔ Load mesh @done (26-01-10 13:36)
 ✔ Import shader-bridge @done (25-10-06 22:26)
 ✔ move to a separate repo @done (25-10-06 22:26)
 ☐ get rid of winit
 ☐ get rid of arboard
 ☐ get rid of egui
 ☐ object picking
 ☐ arbitrary data containers based on archive format
 ☐ Mesh file format
 ☐ Move assets, painting, platform etc. to another crate for potential reuse
 ☐ async asset reloading
 ☐ move egui shaders to shader-archive
 ☐ Deprecate shader-bridge? Move functionality to shadertool
 ☐ crate color should not depend on gpu @high @easy 
    should be the opposite, optional dependency of gpu on color to implement vertex data types
 ✔ buffer pool for uploading stuff to the GPU on each frame (use case: immediate / line rendering) @done (26-01-08 16:12)
 ☐ find a better API than indexing with `Offset<>` to read archives @low
     Relative pointers?
 ☐ "viewport" module/object that bundles the render target (the screen) with utilities to paint things on it (upload buffer, line drawing, etc.) @low
 ✔ GPU: avoid mistake of calling `push_constants` before setting a pipeline @done (25-12-21 17:21)
     setting push constants is now done at the same time as the draw call ("root parameters")
 ✔ shadertool: emit debug-info (dump spirv) @done (25-12-01 23:33)
 ✔ PushConstants (Root paramters) should be a single pointer to GPU memory (No Graphics API) @done (26-01-01 17:12)
     To avoid mistakes like putting an atomic variable in push constants
 ☐ Framework to emit/manipulate geometry from compute shaders in a unified way (polylines, meshes) @low
 ☐ Geometry format: make a generic file format for geometry instead of hard-coding all the different vertex and primitive types
     There are too many types of vertex formats to track, and they must be hard-coded into the file format. 
     New ones are added regularly, which requires changing the file format in a non-backwards-compatible way.
     Replace with a format agnostic geometry container, like houdini geo files, and have usage-specific schemas on top.
 ☐ Generic geometry debugging shader
     Input: geometry in any space (object, world, clip, screen), any format, any primitive kind (mesh, polyline)
     Output: flat shaded, viewport shaded, or wireframe geometry
     This will replace `draw_lines`
 ✔ Simplify buffer and image usages @done (25-12-19 14:23)
     For buffers, in nvk: SSBOs and uniforms have different alignment requirements; as do: device generated commands buffers
     no desktop driver in Mesa has special logic the following buffer bits
         * VK_BUFFER_USAGE_2_VERTEX_BUFFER_BIT / VK_BUFFER_USAGE_VERTEX_BUFFER_BIT 
         * VK_BUFFER_USAGE_2_INDEX_BUFFER_BIT  / VK_BUFFER_USAGE_INDEX_BUFFER_BIT 
         * VK_BUFFER_USAGE_2_TRANSFER_SRC_BIT / VK_BUFFER_USAGE_TRANSFER_SRC_BIT (except one broadcom driver) 
         * VK_BUFFER_USAGE_2_TRANSFER_DST_BIT / VK_BUFFER_USAGE_TRANSFER_DST_BIT
         * VK_BUFFER_USAGE_2_SHADER_DEVICE_ADDRESS_BIT
         * VK_BUFFER_USAGE_2_INDIRECT_BUFFER_BIT
     nvk uses the STORAGE and UNIFORM bits to determine the minimum alignment (STORAGE is 16, UNIFORM is 64); STORAGE is not used meaningfully anywhere else
     Image usages are harder to simplify
  ✔ Barriers are misleading: it is expected to call barrier **before** an operation to set the write flags, and then **after** the operation to sync with the next @done (26-01-08 16:12)
      Split barriers in two
  ✔ Inline root constants at draw call site @done (26-01-02 16:22)
  ☐ Streamline the API even more
      What we're mostly doing now
         * allocating or reallocating buffers and images and storing them in structs
         * pushing root constants
         * creating (useless) encoders for render passes
      Maybe allocate buffers declaratively, like how pipelines are specified in json.
      Not sure if it's worth it at this state, when the render pipeline isn't fully defined
  ✔ GPU: split wait, submits, signals and presents into separate free functions (`gpu::wait`, `gpu::submit`, `gpu::signal` ...) @done (26-01-07 10:27)
      This generates more calls to `vkQueueSubmit` than necessary, but the overhead is insignificant and this makes the API more flexible and readable.
         

 ✔ @high Figure out a way to not need `reference_resource` anymore. @done (25-12-21 18:24)
     Problem: `reference_resource` is needed because the layer has no way to know which resources are used when using bindless resources (texture descriptor indices & buffer addresses).
         Similar approach in Metal with `useResource`
     Possibly: make it the user responsibility to track which frames are using the resource.
     User would call `resource.delete_later(frame_number)`. 
     Emit warning when resource is dropped without waiting for a frame first.
     Advantage: no more tracking of frame numbers per-resource.
     Drawbacks: each system needs to keep track of how their resources are used. This means
         * one more field for the last frame number
         * replacing/reallocating resources is not a simple assignment anymore; for example, if a struct field contains a resource, must move from it first, then call delete_later, then replace;
           this means that resource fields should be "Option<Resource>" to represent the intermediate state between delete_later and the reallocation. This is inacceptable.
     Alternative: make resources entirely unsafe
         i.e. they are `Copy` structs that are nothing more than vulkan handle + some useful metadata
              no destructors, actually no RAII at all; they must be destroyed explicitly. 
     Solution: on drop, just assume that the dropped resource may be used by pending command streams


 ✔ Do away with encoders @done (25-12-19 17:01)
     ComputeEncoder is strictly useless

 ☐ GPU API streamline: render targets @low
    Currently, to add a render target to a fragment shader, you need to
    * (1) add a field to the app struct to store the new render target
    * (2) add code in ctor to create the render target
    * (3) add code in window_event to resize the render target 
    * (4) modify the begin_rendering call to add the new color attachment
    * (5) modify shaders.toml to declare the color attachment
    * (6) add the color field in the FragmentOutput struct
    * (7) finally, in the fragment shader, write to the new color field <-- this is the only thing that matters
    That's SEVEN different locations to modify existing code, and thus SEVEN opportunities to add new bugs. This is too much. 
    The plan
    * can't do much about (6) and (7)
    * (5) can be inferred from the return type of the fragment shader, although you'd still need to declare the blending mode and format somewhere
        * possibly as attributes in FragmentOutput: `[format(RGBA8)][blend=...]`
            * but then you'd have to specify that on every fragment output struct; would need to deduplicate them
        * Note that it's possible (but unlikely) that we'd like to use the same fragment shader in different pipelines, with possibly different attachment formats and blending modes
    * (1,2,3) render targets could be automatically allocated and resized by the application, from an entry in the manifest
    * (4) change begin_rendering parameters to take a graphics pipeline instead. Graphics pipeline would have reflection data that would tell which render target to bind.
        * `let mut encoder = renderer.begin_pass("name")`
        * in shaders, FragmentOutput fields would have an attribute that specifies which RT to write to `[render_target("main_color")]`
            * and maybe, the color to clear the render target to
        * the specifics of the render targets would be written in shaders.toml (the format will be extended to describe pipeline resources as well)

    After the proposal
    * (1) Add a color field to the FragmentOutput struct, with the `[render_target("name")]` attribute
    * (2) In the fragment shader, write the color field
    * (3) Modify shaders.toml to declare the new color attachment for the pipeline
    * (4) Modify shaders.toml to declare a new render target resource
    Rust code doesn't need to change anymore.

    Going further, we can skip (3) entirely if the blending mode is specified in FragmentOutput.

 ☐ GPU API streamline 2: scripting
     It's useless if there's no autocompletion for the pass names and parameters.
 ✔ Global tweakable variables @done (26-01-12 12:38)
     In rust code, call `tweak::<T>(min, max)` to automatically show a slider in the GUI
 ☐ QoL: remember last application state and reload (geometry file, pipeline config)
 ☐ Global settings singleton
 ☐ GPU: queries
     Timestamp queries
 ☐ GPU API streamline: resource sizes in shaders
     It would be extremely useful to specify the required sizes for intermediate buffers directly in shaders, next to where they are used.
     Size of intermediate resources are usually a multiple of some application value, like the number of vertices in the geometry, or the size of the screen.
     Thus shaders would pass an expression (or a multiple) to determine the size of a buffer.
 ☐ GPU streamlined: allocate buffers in compute shaders
     Another option would be to allocate resources directly in the shaders. Basically a memory allocator, but on the device timeline.
     A simple per-frame bump allocator, with a limit. 
     Single-thread compute shader runs to perform the allocation and initialize pointers.
     Also, kick off rendering and other compute passes from compute shaders, with DrawIndirect/DispatchIndirect
         In compute shader, `DispatchIndirect(pass_id, 1, 1, 1)` will write to a DispatchParams command and 
     Basically investigate VK_EXT_device_generated_commands


Render world:
    The "render world" holds all resources, pipelines, and is in charge of running the render passes. It also holds the current scene to draw.
    The resources and render passes are defined declaratively in a separate file.
    Draw parameters, like the number of vertices and indices, depend on the scene. They are determined automatically.
    For some compute passes, which require a number of workgroups to be launched that depend on some block or tile size, this is more complicated, but we can get around it by specifying the tile size.
    Each object in the "render world" has a name (identifier) and a type. The type can be opaque for now, but it should at least differentiate between geometry buffers & one-off variables.


Models:
    ☐ Outlines
    ☐ Salient edges
    ☐ Convex patch decomposition
    ☐ Armature
    ☐ Figure out representation for "crease edges"
        Split points: if multiple houdini vertices share the same point AND vertex normal, then fuse them into a single "mesh vertex" (the usual)
        Indexed vertex attributes: each vertex sent to the GPU has two indices
            * a vertex index to query vertex level attributes
            * a point index for point attributes
            This requires two lookups. Most of the time, point == vertex index

Contours:
    ☐ Differentiate boundaries from outlines
    ☐ Contour enhancement: silhouette ends
    ☐ Contour enhancement: silhouette segmentation
    ☐ Contour enhancement: depth difference
    ☐ Line-art map:
        ☐ Object position
        ☐ Normal 
        ☐ View depth
        ☐ Contour type: silhouette, outer silhouette, boundaries, intersections, explicit lines
        ☐ Segmentation index
        ☐ Structure information: corner, T-junction, end
        ☐ Authored arclength 
        ☐ Authored width
        ☐ Authored layer index
        ☐ Authored color
        ☐ Bone index
    
What we have now: lineart map with: ss normal angle, group id
Need to expand that into strokes. Possible approaches
* compute distance field from lineart pixels

Experiment
* [compute shader] chain all contour edges into connected components
    contour_extraction: outputs cluster index + two global point indices
    chain_edges: sort edges by point indices
        sorting isn't correct: you can have loops

* [compute shader] fuse close points
* [compute shader] subdivide 

Terrain rendering:
    ✔ Find out how to do the initial adaptive meshing @done (25-12-15 15:55)
    ☐ Draw the initial meshing
    ☐ use meshoptimizer to create clusters
    ☐ build the cluster hierarchy


World:
    ☐ Character navigation
        ☐ Navmeshes
    ☐ Third-person camera
    ☐ Character collision
    ☐ Animation
        ☐ Limb IK
    ☐ Lighting
    ☐ Mesh import
    ☐ Skinning & animated characters


2D rendering:
    ☐ Use case: GUI
    ☐ Use case: 3D overlay
    ☐ Use case: load/save vector drawings
    ☐ Use case: sprites
    ☐ Test harness for rendering
    ✔ Text @done (25-10-04 23:30)
    ☐ Font selection by name

Shaders:
    ✔ [shader-bridge] `struct ShaderLibrary`: represents a loaded/parsed slang source file (in shader-bridge), as a collection of entry points; used to retrieve ShaderEntryPoint objects @done (25-10-06 22:25)
    ✔ [shader-bridge] `struct ShaderEntryPoint`: represents a shader entry point, associated SPIR-V code & useful reflection data @done (25-10-06 22:25)

Direction:
    ☐ Figure out terrain representation 
    ☐ Repr: construction grids
    ☐ Repr: caves & cliffs
    ☐ Repr: artificial structures
    ☐ Repr: vegetation
    ☐ Repr: atmospheric effects / ambience
    ☐ Figure out object picking technique
    ☐ Identifying assets (e.g. some object references a font, then the name of the font is renamed; how do we identify the font?)
        ☐ Identify assets with GUIDs (within a project)
    ☐ Managing associated resources & cached resources
        ☐ E.g. if a font file is unloaded, should also free its associated cache entry in the global FontCollection
        ☐ E.g. if an image is unloaded, should also free associated GPU textures

Ideas:
    ☐ Idea: take satellite maps as input (w/ elevation) & generate stylized landscape from that, by pattern recognition
    ☐ Simulate electrical/communication networks

--- ✄ -----------------------


EGUI replacement:
    ✔ unify geometry/vector types via external crate (math) @done (25-10-06 22:26)
    ✔ draw rectangles @done (25-10-06 22:26)
    ✔ draw rounded rectangles @done (25-10-06 22:26)
    ☐ space allocation & layout
    ✔ text layout & rendering @done (25-10-06 22:26)

Winit replacement:
    ☐ create win32 window
    ☐ Win32 event loop
    ☐ mouse (WM_POINTER) events
    ☐ keyboard event translation
    ☐ resizing
    ☐ custom cursors 
    ☐ clipboard

Event loop:
    ☐ Figure out callbacks
        Async? Too restrictive, must wrap stuff in Arcs or Rc<RefCell>
        The most intuitive model is the current one: a single static `App` object holding the state. Callbacks can refer to it without capturing anything.
        However, this requires the whole application state to be visible to all components: it's not very decoupled.
        Proposal: individual components can't request to be called back directly; instead the application must route all events manually to all components
            -> not very well decoupled
        Proposal: application components are `'static`
            They *are* static in practice. 
            But the reference we get when we borrow the RefCell sure isn't.
            `&self` can be moved into callbacks, but it will need interior mutability.
                Technically, when callbacks are called from the top of the event loop, it's almost sure that nothing holds a borrow of the component.
        Proposal: store independent application components in separate statics
            There's no need to stuff everything into App if the stuff is decoupled anyway.
        Red lines: no Rc, no RefCells
            ergonomic impact is too much

Bugs:
    ☐ vkDestroySemaphore(): can't be called on VkSemaphore 0xcb1c7c000000001b[DxgiVulkanSharedFence] that is currently in use by VkQueue 0x1be997ad4c0.
    ☐ ERROR_DEVICE_LOST sometimes at startup
        \Device\Video3
        Error occurred on GPUID: 700
